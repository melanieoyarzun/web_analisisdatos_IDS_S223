{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "institute: Magíster en Data Science - Universidad del Desarrollo\n",
        "subtitle: 'Curso: Análisis de datos'\n",
        "title: |-\n",
        "  Sesión 1: Planteando y respondiendo preguntas con datos. \n",
        "   (y un -breve- repaso a pruebas de hipótesis)\n",
        "author: 'Phd (c) Melanie Oyarzún - [melanie.oyarzun@udd.cl](mailto:melanie.oyarzun@udd.cl)'\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    html-math-method: mathml\n",
        "    embed-resources: true\n",
        "  ipynb: default\n",
        "echo: true\n",
        "editor:\n",
        "  markdown:\n",
        "    wrap: 72\n",
        "execute:\n",
        "  keep-ipynb: true\n",
        "  freeze: auto\n",
        "code-link: true\n",
        "---"
      ],
      "id": "eee101d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detalles {.unnumbered .unlisted visibility=\"hidden\"}\n",
        "\n",
        "Notas detalladas de la sesión 1, curso análisis de datos, magíster en\n",
        "Data Science Universidad del Desarrollo.\n",
        "\n",
        "Fecha: 19 agosto 2023. Versión 1\n",
        "\n",
        "## Objetivos de aprendizaje de la sesión\n",
        "\n",
        "1.  Comprender el papel del proceso de adquisición y almacenamiento en\n",
        "    un proyecto de análisis de datos, junto a buenas prácticas que\n",
        "    promuevan la transparencia y replicabilidad.\n",
        "2.  Aprender a formular preguntas y plantear hipótesis que puedan ser\n",
        "    abordadas mediante el análisis de datos.\n",
        "3.  Desarrollar la habilidad de realizar pruebas de hipótesis y\n",
        "    comprender la interpretación de sus resultados.\n",
        "\n",
        "## Contenidos:\n",
        "\n",
        "#### El proceso de análisis de datos {.unnumbered .unlisted}\n",
        "\n",
        "1.  **El proceso de análisis de datos**\n",
        "    -   Una visión general a las metodologías de análisis que veremos en\n",
        "        el curso\n",
        "    -   Adquision y almacenmiento de los datos\n",
        "    -   Preparación de los datos\n",
        "2.  **Preguntando a los datos**\n",
        "    -   Asbtrayendo la realidad, variables aleatorias y probabilidades.\n",
        "    -   Planteamiento de preguntas.\n",
        "    -   Preguntas y respuestas: el rol de las hipótesis.\n",
        "\n",
        "#### Respondiendo desde los datos: Pruebas de hipótesis {.unnumbered .unlisted}\n",
        "\n",
        "1.  **Conceptos Básicos de Pruebas de Hipótesis:**\n",
        "    -   Definición de hipótesis nula y alternativa.\n",
        "    -   Niveles de significancia y p-values.\n",
        "    -   Errores tipo I y tipo II.\n",
        "2.  **Tipos de Pruebas de Hipótesis:**\n",
        "    -   Pruebas t para comparación de medias.\n",
        "    -   Pruebas chi-cuadrado para variables categóricas.\n",
        "    -   Pruebas ANOVA para comparación de múltiples grupos.\n",
        "3.  **Interpretación de Resultados:**\n",
        "    -   Evaluación de p-values y toma de decisiones.\n",
        "    -   Significación estadística vs. significación práctica.\n",
        "    -   Comunicación de los resultados de las pruebas de hipótesis.\n",
        "\n",
        "#### Buenas prácticas en análisis de datos {.unnumbered .unlisted}\n",
        "\n",
        "1.  **Desafíos y Consideraciones:**\n",
        "    -   Privacidad y seguridad de los datos.\n",
        "    -   Limpieza y transformación durante la preparación de datos.\n",
        "2.  **Reproducibilidad y Control de Versiones (GIT):**\n",
        "    -   Importancia de mantener un registro de los cambios en los datos.\n",
        "    -   Uso de sistemas de control de versiones como GIT para rastrear\n",
        "        cambios.\n",
        "    -   Aplicación de control de versiones en proyectos de preparación\n",
        "        de datos.\n",
        "\n",
        "## El proceso de análisis de datos\n",
        "\n",
        "En el mundo actual, la generación y recopilación de datos se ha vuelto\n",
        "más accesible y significativa que nunca antes. Esta abundancia de\n",
        "información ofrece la oportunidad de extraer conocimientos valiosos que\n",
        "pueden influir en la toma de decisiones y el desarrollo de soluciones\n",
        "eficientes.\n",
        "\n",
        "Sin embargo, el proceso de transformar estos datos crudos en información\n",
        "útil y significativa requiere una serie de pasos fundamentales que\n",
        "forman parte integral de la disciplina conocida como Ciencia de Datos.\n",
        "\n",
        "![](img/objetivo_ds.png)\n",
        "\n",
        "En esta primera parte, daremos un vistazo general a las metodologías y\n",
        "enfoques clave que exploraremos a lo largo del curso, con énfasis en la\n",
        "importancia de la preparación de los datos.\n",
        "\n",
        "El proceso de análisis de datos se puede dividir en varias etapas\n",
        "interconectadas, cada una con su propio conjunto de desafíos y\n",
        "consideraciones.\n",
        "\n",
        "![](img/proceso_datascience.png)\n",
        "\n",
        "Bajo esta mirada, tenemos varias fases clave que están interconectadas.\n",
        "En este curso nos enfocaremos en la preparación de los datos y en su\n",
        "análisis mediante modelos de regresión. Esto con el objetivo de\n",
        "responder preguntas desde los datos, que provean información valiosa.\n",
        "\n",
        "### Adquisición de datos:\n",
        "\n",
        "El primer paso en el proceso de análisis de datos implica la adquisición\n",
        "y el almacenamiento de los datos. Esto se refiere a la recolección de\n",
        "los datos necesarios para abordar una pregunta o problema en particular.\n",
        "\n",
        "Puede implicar la recopilación de datos de fuentes diversas, como bases\n",
        "de datos, archivos CSV, páginas web o incluso sensores en tiempo real.\n",
        "\n",
        "Es crucial comprender cómo recopilar y almacenar estos datos de manera\n",
        "adecuada, garantizando su calidad, integridad y seguridad.\n",
        "\n",
        "Existen tantas fuentes de datos, como podríamos imaginar. ALgunas de las\n",
        "más comunes son las siguientes:\n",
        "\n",
        "1.  **Encuestas y Cuestionarios:**\n",
        "    -   Diseño y administración de encuestas para recopilar datos\n",
        "        directamente de los participantes.\n",
        "    -   Permite obtener información específica y detallada según las\n",
        "        preguntas planteadas.\n",
        "2.  **Experimentos Controlados:**\n",
        "    -   Diseño de experimentos para recopilar datos bajo condiciones\n",
        "        controladas.\n",
        "    -   Útil para establecer relaciones causales y evaluar efectos de\n",
        "        cambios controlados.\n",
        "3.  **Observación y Sensores:**\n",
        "    -   Uso de sensores y dispositivos para capturar datos en tiempo\n",
        "        real.\n",
        "    -   Ampliamente utilizado en aplicaciones IoT (Internet of Things)\n",
        "        para monitorizar y recopilar información ambiental.\n",
        "    -   Utilización de sensores en dispositivos móviles y wearables para\n",
        "        recopilar datos de ubicación, salud y actividad.\n",
        "4.  **Recopilación de Datos Existentes:**\n",
        "    -   Utilización de datos ya recopilados y disponibles en bases de\n",
        "        datos o fuentes públicas.\n",
        "    -   Reduce el tiempo y costo de recopilación, pero puede tener\n",
        "        limitaciones en términos de calidad y relevancia.\n",
        "5.  **Web Scraping (Web Scrapping):**\n",
        "    -   Extracción de datos de sitios web utilizando herramientas y\n",
        "        técnicas automatizadas.\n",
        "    -   Permite recopilar información no estructurada de manera\n",
        "        eficiente, pero requiere atención a la ética y términos de uso.\n",
        "6.  **Acceso a APIs (Application Programming Interfaces):**\n",
        "    -   Interacción programática con sistemas y servicios para obtener\n",
        "        datos en tiempo real.\n",
        "    -   Común en la obtención de datos de redes sociales, información\n",
        "        climática, finanzas, entre otros.\n",
        "7.  **Colaboración y Participación Comunitaria:**\n",
        "    -   Colaboración con comunidades y grupos para recopilar datos de\n",
        "        manera colectiva.\n",
        "    -   Puede ser útil para proyectos de mapeo colaborativo, ciencia\n",
        "        ciudadana y recopilación de información local.\n",
        "8.  **Data Lakes y Almacenamiento en la Nube:**\n",
        "    -   Almacenamiento de grandes volúmenes de datos sin estructura\n",
        "        definida en sistemas de almacenamiento en la nube.\n",
        "    -   Facilita la recopilación y posterior análisis de datos\n",
        "        heterogéneos.\n",
        "    -   Usualmente se accede a través de querys SQL\n",
        "\n",
        "::: callout-tip\n",
        "#### Datos disponibles para el proyecto\n",
        "\n",
        "En nuestro proyecto vamos a usar datos de tres posibles fuentes:\n",
        "\n",
        "1.  Datos públicos sobre educación chilena\n",
        "2.  Datos públicos sobre adjudicaciones municipales\n",
        "3.  Datos publicos sobre individuos en comunas chilenas (encuesta Casen)\n",
        "4.  Datos sobre crecimiento de paises y complejidad económica\n",
        "\n",
        "Veamos como acceder algunos de estos datos.\n",
        ":::\n",
        "\n",
        "**Ejemplo: Datos públicos sobre individuos en comunas chilenas (encuesta\n",
        "Casen)**\n",
        "\n",
        "La Encuesta de Caracterización Socioeconómica Nacional (CASEN) es una\n",
        "investigación realizada en Chile que tiene como objetivo principal\n",
        "recopilar información detallada sobre la situación socioeconómica de los\n",
        "hogares y las personas en el país. Esta encuesta se lleva a cabo de\n",
        "manera periódica y abarca una amplia variedad de temas, como ingresos,\n",
        "educación, empleo, salud, vivienda y otros aspectos relevantes para\n",
        "comprender la realidad socioeconómica de la población chilena. La\n",
        "información recopilada en la Encuesta CASEN se utiliza para informar\n",
        "políticas públicas, tomar decisiones informadas y analizar la evolución\n",
        "de indicadores sociales a lo largo del tiempo.\n",
        "\n",
        "[Sitio Web\n",
        "oficial](https://observatorio.ministeriodesarrollosocial.gob.cl/encuesta-casen)\n",
        "\n",
        "Si tenemos los datos alojados en una dependencia, simplemente los\n",
        "cargamos. El formato mas comun es .csv, pero a veces estan en formatos\n",
        "extraños. Por ejemplo, .dta de STATA.\n"
      ],
      "id": "0d4ae89b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_casen2020= pd.read_stata(\"https://github.com/melanieoyarzun/taller_seriestiempo_IDS/blob/b0be4e78a8c7a738e41b284a65d350179abbda96/Data/casen_2020_ingresos.dta?raw=true\")\n",
        "\n",
        "df_casen2020.head(5)"
      ],
      "id": "b55cf546",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez cargados los datos, debemos proceder a su limpieza y\n",
        "exploración, para ser preparados para analizarlos. De esto se tratará la\n",
        "siguiente sesión del curso.\n",
        "\n",
        "**Ejemplo: Datos desde la API del banco mundial** Primero siga este\n",
        "ejemplo practico de importar datos, luego será facil responder la\n",
        "pregunta anterior.\n"
      ],
      "id": "e7969f84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#pandas remote data access support for calls to the World Bank Indicators API\n",
        "\n",
        "from pandas_datareader import data, wb # para instalar: conda install pandas-datareader  o  pip install pandas-datareader\n",
        "\n",
        "#Revisemos que indicadores hay disponibles. En este caso revisare de PIB (GDP en ingés), pero se pueden explorar muchas más opciones.\n",
        "\n",
        "wb.search('gdp')"
      ],
      "id": "ff5ed38a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Obtengamos la lista de paises disponibles\n",
        "countries=wb.get_countries()\n",
        "\n",
        "#Preview primeras filas lista de paises\n",
        "countries[:5]"
      ],
      "id": "c76d1aa7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observar que este es un data frame con dos índices: pais y año. Para\n",
        "mayor referencia coo tratar este tipo de datos ver en\n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html\n",
        "\n",
        "Obtengamos un data frame con los datos de Chile, entre 1980 y 2020.\n"
      ],
      "id": "b1500c8b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sabemos que queremos Chile, asi que busquemos su info\n",
        "\n",
        "countries[ countries['name'] == 'Chile' ]\n",
        "\n",
        "# Descarguemos la data desde la API del banco mundial a un dataframe\n",
        "\n",
        "df_GPDpc_Chile = wb.download(\n",
        "                    #Use the indicator attribute to identify which indicator or indicators to download\n",
        "                    indicator='NY.GDP.PCAP.KD',\n",
        "                    #Use the country attribute to identify the countries you want data for\n",
        "                    country=['CL'],\n",
        "                    #Identify the first year for which you want the data, as an integer or a string\n",
        "                    start='1980',\n",
        "                    #Identify the last year for which you want the data, as an integer or a string\n",
        "                    end=2020\n",
        "                )\n",
        "\n",
        "df_GPDpc_Chile.info()"
      ],
      "id": "3a733b9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Veamos el data frame\n",
        "df_GPDpc_Chile.head()"
      ],
      "id": "5f8dff2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si quisieramos, por simplicidad quedarnos solo con el indice del año y\n",
        "reordenar el dataframe:\n"
      ],
      "id": "28fa5baa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_GPDpc_Chile.droplevel('country')\n",
        "\n",
        "\n",
        "reversed_df = df_GPDpc_Chile.iloc[::-1] #invertimos el dataframe \n",
        "reversed_df= reversed_df.droplevel('country') # removemos el level pais, ya que todo el análisis es para un solo país\n",
        "reversed_df.head(5)"
      ],
      "id": "a709a5df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, realicemos un grafico rápido con nuestros datos:\n"
      ],
      "id": "2b7b73e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Graficamos\n",
        "\n",
        "ax = df_GPDpc_Chile['1980':].plot(legend=False) \n",
        "ax.set_ylabel(r'GDP')\n",
        "ax.set_xlabel(r'Año')"
      ],
      "id": "7f3687a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: callout-warning\n",
        "#### Taller 1: Pregunta 1 - Bajando y formateando datos del Banco Mundial\\*\\*\n",
        "\n",
        "Replique el ejemplo práctico de importar datos desde la API del Banco\n",
        "Mundial y empezar la base para su análisis de series de tiempo.\n",
        "\n",
        "Importe usted la serie de GDP total Y Percapita para otro país serie\n",
        "desde la API del Banco mundial, muestre sus principales características\n",
        "y realice un grafico.\n",
        "\n",
        "**¿pareciera haber tendencias?**\n",
        ":::\n",
        "\n",
        "### Preguntando a los datos\n",
        "\n",
        "¿Cómo plantear preguntas y formular hipótesis en el contexto del\n",
        "análisis de datos? El proceso de análisis comienza con la curiosidad y/o\n",
        "necesidad.cLa formulación de preguntas relevantes que se puedan\n",
        "responder mediante la exploración y el examen de los datos disponibles.\n",
        "\n",
        "Inicia con la identificación de áreas de interés y la formulación de\n",
        "preguntas específicas relacionadas con esos temas. Estas preguntas\n",
        "pueden surgir de la necesidad de resolver un problema, entender un\n",
        "fenómeno o explorar patrones en los datos. Un buen planteamiento de\n",
        "preguntas es crucial, ya que guiará todo el proceso de análisis.\n",
        "\n",
        "![El proceso de abstraer la realidad](img/abstraccionpng.png)\n",
        "\n",
        "**Preguntas e hipótesis:**\n",
        "\n",
        "Una hipótesis es una afirmación, verificable con evidencia. En este\n",
        "sentido, para toda pregunta podemos responderla mediante hipótesis.\n",
        "\n",
        "En particular, para responder a las preguntas en el contexto de datos,\n",
        "es común formular hipótesis nulas y alternativas.\n",
        "\n",
        "La hipótesis nula es aquella que propone que algun parámetro toma cierto\n",
        "valor. Este generlamente es un punto de verdad. Si bien, con datos no\n",
        "podemos corroborar que algo es cierto, si podemos dar evidencia de que\n",
        "no es cierto. En general, planteamos el problema de tal manera que\n",
        "podamos rechazar la hipótesis nula, en favor de otra que llamamos\n",
        "alternatiba.\n",
        "\n",
        "Quizas, la hipotesis nula más famosa es la prueba de \"significancia\". En\n",
        "esta se propone que un parámetro (muchas veces un efecto, o correlación)\n",
        "es 0, es decir, plantea que no hay efecto o relación entre las\n",
        "variables, mientras que la hipótesis alternativa sugiere que sí existe\n",
        "una relación o efecto significativo.\n",
        "\n",
        "Estas hipótesis son fundamentales para establecer una base objetiva para\n",
        "el análisis y para evaluar las evidencias encontradas en los datos. El\n",
        "proceso de plantear preguntas y formular hipótesis es el primer paso en\n",
        "el análisis de datos, ya que establece una guía clara para el enfoque y\n",
        "la dirección del trabajo. **Al identificar preguntas y establecer\n",
        "hipótesis, se crea un marco sólido que orientará la exploración y el\n",
        "análisis de los datos disponibles.**\n",
        "\n",
        "::: callout-warning\n",
        "#### Taller 1: Pregunta 2 - Investigando sobre países:\n",
        "\n",
        "Considere que tenemos los datos del banco mundial, del país que\n",
        "selecciono anteriormente, y desea aprender sobre alguna caracterpistica\n",
        "de dicho pais en el periodo.\n",
        "\n",
        "Escriba una pregunta de investigación que se pueda responder con los\n",
        "datos disponibles. ¿Cómo definiria la variable aleatoria relevante? ¿Qué\n",
        "hipótesis podria responder su pregunta?\n",
        ":::\n",
        "\n",
        "## Respondiendo desde los datos\n",
        "\n",
        "### Inferencia estadística\n",
        "\n",
        "Inferencia se refiere al proceso de hacer generalizaciones de una\n",
        "población a partir de una muestra de esa población. En particular, la\n",
        "idea es que si tenemos un conjunto de datos (muestra) obtenido de una\n",
        "población más grande, el cual es representativo de esta, podemos\n",
        "utilizar métodos estadísticos para sacar conclusiones sobre las\n",
        "características y propiedades de esa población en su totalidad.\n",
        "\n",
        "![Población y Muestra](img/poblacion_muestra.png)\n",
        "\n",
        "El proceso de inferencia estadística se basa en el principio de que una\n",
        "muestra bien seleccionada puede proporcionar información valiosa sobre\n",
        "la población en general. Mediante el análisis de la muestra, podemos\n",
        "estimar parámetros poblacionales, como la media, la proporción o la\n",
        "desviación estándar, y también podemos construir intervalos de confianza\n",
        "para estimar el rango dentro del cual se espera que se encuentren estos\n",
        "parámetros.\n",
        "\n",
        "El uso de la inferencia estadística es fundamental, especialmente si es\n",
        "impracticable o costoso analizar cada elemento de una población en\n",
        "particular. Por ejemplo, en lugar de encuestar a todos los ciudadanos de\n",
        "un país, es mucho más factible encuestar una muestra representativa y\n",
        "utilizar esa información para hacer suposiciones sobre la opinión de la\n",
        "población en general.\n",
        "\n",
        "#### Estadígrafos y el Teorema del Límite central\n",
        "\n",
        "Entonces, en cada muestra que tenemos podemos calcular aproximaciones a\n",
        "los parámetros poblacionales de interés. Estos son los llamados\n",
        "**estadísgrafos** ![Estadigrafos](img/estadigrafos.png)\n",
        "\n",
        "Dado que por cada muestra que tenemos, vamos a calcular un estadígrafo\n",
        "este es en si mismo una variable aleatoria. Tiene su propia\n",
        "distribución, media y varianza!\n",
        "\n",
        "![](img/distribuciones_estadigrafos.png)\n",
        "\n",
        "El estadígrafo más conocido es el promedio o media muestral.\n",
        "\n",
        "![Estadigrafos más comunes](img/tabla_estadigrafoscomunes.png)\n",
        "\n",
        "Cada estimador es una función de la muestra, por ende para cada muestra\n",
        "que tengamos obtendremos un valor numérico específico para el estimador.\n",
        "Por este motivo, cuando estamos trabajando con una única muestra\n",
        "específica, tenemos un único valor del estimador, o estimador puntual.\n",
        "\n",
        "Nunca (o casi nunca) podemos conocer el valor verdadero de los\n",
        "parámetros en la población, por lo cual un primer camino tentador es\n",
        "usar el estimador puntual para tomar una decisión. Como nunca podemos\n",
        "conocer el verdadero parámetro, tampoco podemos saber a ciencia cierta\n",
        "si el estimador puntual es cercano a este.\n",
        "\n",
        "**¿Cómo conectamos estadpigrafos y parámetros?**\n",
        "\n",
        "El teorema del límite central, nos dice que, bajo ciertas condiciones,\n",
        "la distribución de las medias muestrales de una población se aproxima a\n",
        "una distribución normal a medida que el tamaño de la muestra aumenta,\n",
        "independientemente de la forma de la distribución original de la\n",
        "población. Este teorema es esencial en inferencia estadística y tiene\n",
        "amplias aplicaciones en análisis de datos y toma de decisiones.\n",
        "\n",
        "![La media muestral se distribuye normal, sin importar la distribución\n",
        "de la variable subyacente](img/promedio_TLC.png)\n",
        "\n",
        "Formalmente, el Teorema del Límite Central establece lo siguiente:\n",
        "\n",
        "$$\\bar{x} \\sim_a N(\\mu, \\frac{\\sigma}{\\sqrt{n}}) $$\n",
        "\n",
        "Supongamos que tenemos una población con media μ y desviación estándar σ\n",
        "finitas. Si tomamos muestras aleatorias de tamaño n de esta población y\n",
        "calculamos la media muestral de cada muestra, entonces, a medida que n\n",
        "tiende a infinito, la distribución de estas medias muestrales se\n",
        "aproximará a una distribución normal con media μ y desviación estándar\n",
        "σ/√n.\n",
        "\n",
        "En otras palabras, sin importar la distribución original de la\n",
        "población, cuando el tamaño de la muestra es suficientemente grande, la\n",
        "distribución de las medias muestrales seguirá una forma de campana\n",
        "similar a la distribución normal. Este resultado es fundamental para\n",
        "realizar inferencias sobre la población a partir de muestras, ya que nos\n",
        "permite aplicar métodos basados en la distribución normal incluso cuando\n",
        "la población original no sigue una distribución normal.\n",
        "\n",
        "#### Error estándar\n",
        "\n",
        "-   Corresponde a un estimador de la desviación estándar del estimador.\n",
        "\n",
        "-   Identifica que tan lejos estamos del verdadero valor poblacional.\n",
        "\n",
        "-   Para la **media muestral**:\n",
        "\n",
        "$$ SE = \\frac{S_y}{\\sqrt{n}}$$\n",
        "\n",
        "Se utiliza para evaluar a los estimadores, mediante *pruebas de\n",
        "hipotesis* y construir *intervalos de confianza*\n",
        "\n",
        "-   Si se conoce un estimador y su desviación estándar, podemos saber\n",
        "    qué tan precisa es la estimación (mucha o poca varianza), pero no\n",
        "    podemos saber si el estimador está cercano o no a su valor verdadero\n",
        "    en la población (el cual no conocemos).\n",
        "\n",
        "-   Nunca (o casi nunca) podemos conocer el valor verdadero de los\n",
        "    parámetros en la población.\n",
        "\n",
        "-   Sí se puede construir un conjunto de valores que contienen el\n",
        "    parámetro poblacional con alguna probabilidad (llamada el nivel de\n",
        "    confianza).\n",
        "\n",
        "-   Un intervalo de confianza contiene los posibles valores del\n",
        "    estimador, entre un límite inferior y un límite superior, con cierta\n",
        "    probabilidad.\n",
        "\n",
        "#### Inferencia sobre Estadígrafos y parámetros - Conectados por el Teorema del Límite central\n",
        "\n",
        "$$ \\bar{x} \\sim_a N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)$$\n",
        "\n",
        "-   Con este teorema, podemos construir inferencia de \\mu a partir de\n",
        "    \\bar{x} indirectamente.\n",
        "    -   Intervalos de confianza\n",
        "    -   Pruebas de hipótesis\n",
        "    -   p-valor\n",
        "\n",
        "### Intervalos de confianza\n",
        "\n",
        "Una primera manera de aproximarnos a los parámetros poblacionales\n",
        "(particularmente a la esperanza) es mediante la construcción de\n",
        "intervalos de confianza.\n",
        "\n",
        "![](img/intervalo_dist.png)\n",
        "\n",
        "Un intervalo de confianza contiene los posibles valores del estimador,\n",
        "entre un límite inferior y un límite superior, con cierta probabilidad.\n",
        "\n",
        "![](img/intervalo_dist2.png)\n",
        "\n",
        "¿De dónde saco los valores críticos?\n",
        "\n",
        "Los valores críticos de una distribución los obtenemos de una tabla de\n",
        "distribución o para calcular podemos usar excel, R o en python:\n",
        "\n",
        "```         \n",
        "scipy.stats.t.isf(alpha, n-p)\n",
        "```\n",
        "\n",
        "Si estamos trabajando con dos colas, usar alpha/2 porque la probabilidad\n",
        "de error la estamos repartiendo a ambas colas.\n",
        "\n",
        "::: callout-note\n",
        "#### \\[Matemáticamente\\] Caso 1: Varianza conocida\n",
        "\n",
        "Sumpongamos que tenemos una muestra aleatoria: $y_1, y_2, \\dots, y_n$ de\n",
        "una población $Y\\sim N(\\mu, \\sigma^2)$\n",
        "\n",
        "-   La media muestral $\\bar{y}= \\frac{1}{n}\\sum_{i=1}{n}y_i$\n",
        "    -   Su esperanza es: $E(\\bar{y}) =\\mu$\n",
        "    -   Su varianza es: $var(\\bar{y}) = \\frac{\\sigma^2}{n}$\n",
        "    -   se distribuye normal, tal que podemos estandarrizar: \\$\n",
        "        \\frac{\\bar{Y} - \\mu_y }{ \\frac{\\sigma}{\\sqrt{n}}} \\sim N(0,1) \\$\n",
        "\n",
        "Entonces, podemos describir que:\n",
        "\n",
        "\\$ P( -1.96 \\< \\frac{\\bar{Y} - \\mu_y }{ \\frac{\\sigma}{\\sqrt{n}}} \\< 1.96\n",
        ") = 0.95 \\$\\$\n",
        "\n",
        "\\$ P( \\bar{y}-\\frac{1.96\\sigma }{\\sqrt{n}} \\< \\mu \\< \\bar{y} +\n",
        "\\frac{1.96\\sigma }{\\sqrt{n}} ) = 0.95 \\$\n",
        "\n",
        "-   este intervalo es aleatorio, porque $\\bar{y}$ es diferente en cada\n",
        "    muestra.\n",
        "\n",
        "-   para el 95% de las muestras elatorias, el intervalo construido de\n",
        "    esta manera contendrá a $\\mu$\n",
        ":::\n",
        "\n",
        "::: callout-note\n",
        "#### \\[Matemáticamente\\] Caso 2: Varianza desconocida\n",
        "\n",
        "-   Supongamos que tenemos una muestra aleatoria $y_1, y_2, \\dots, y_n$\n",
        "    de una población $y\\sim N(\\mu, \\sigma^2 )$\n",
        "\n",
        "-   Usamos la estimación de la desviación estándar muestral:\n",
        "    $$ S_y = \\sqrt{\\frac{1}{n-1} \\sum{i=1}{n}(y_i - \\bar{y})^2} $$\n",
        "\n",
        "-   Y si estandarizamos $\\bar{y}$:\n",
        "    $$ \\frac{\\bar{Y} - \\mu_y }{ \\frac{S}{\\sqrt{n}}} \\sim t_{n-1} $$\n",
        "\n",
        "-   Podeos constrir un intervalo de la porbabilidad de estar al 95 con\n",
        "    el valor critico c adecuado a los grados de libertad n-1:\n",
        "\n",
        "$$ P( -c <   \\frac{\\bar{Y} - \\mu_y }{ \\frac{ S}{\\sqrt{n}}}  < c  ) =0.95  $$\n",
        "\n",
        "$$ P(\\bar{y} - \\frac{c\\times S}{\\sqrt{n}} < \\mu < \\bar{y} + \\frac{c\\times S}{\\sqrt{n}} ) 0.95$$\n",
        "\n",
        "-   Si llamamos al error estandar SE: $SE(\\bar{y})=\\frac{S}{\\sqrt{n}}$\n",
        "\n",
        "-   El IC es:\n",
        "    $$ (\\bar{y} - \\frac{c\\times S}{\\sqrt{n}}, \\bar{y} + \\frac{c\\times S}{\\sqrt{n}} ) $$\n",
        ":::\n",
        "\n",
        "### El intervalo es una muestra aleatoria\n",
        "\n",
        "Esto quiere decir que para cada muestra podemos construir un intervalo.\n",
        "\n",
        "Así como el estimador es una variable aleatoria, esto también es cierto\n",
        "para los intervalos de confianza. Por eso también se les llama\n",
        "intervalos aleatorios, ya que con diferentes muestras obtendremos un\n",
        "diferente estimador e intervalo.\n",
        "\n",
        "Por ende, supongamos que contamos con 20 muestras, entonces\n",
        "construiremos 20 intervalos de confanza diferentes para los 20\n",
        "estimadores puntuales.\n",
        "\n",
        "![](img/intervalo_confianza1.png)\n",
        "\n",
        "**Interpretación de intervalo de confianza**\n",
        "\n",
        "Pensemos en un 95% de confianza (un valor usual). Esto quiere decir, que\n",
        "si se repitiera este ejercicio muchas veces y construyéramos un\n",
        "intervalo de esta forma el 95% de ellos contendría el verdadero\n",
        "parámetro poblacional.\n",
        "\n",
        "Un elemento importante a considerar es que esto no significa que con 95%\n",
        "de certeza el parámetro está exactamente en estos valores. Por ejemplo,\n",
        "al 95% de confianza con 20 intervalos 19 contendrán el parámetro.\n",
        "\n",
        "![](img/intervalo_confianza2.png)\n",
        "\n",
        "### Pruebas de hipótesis\n",
        "\n",
        "-   Una forma de verificar hipotesis sobre los parámetros es mediante el\n",
        "    contraste de hipótesis.\n",
        "\n",
        "Empezamos suponiendo que hay una distribución conocida para el\n",
        "estadígrafo, centrada en un valor específico. Y nos preguntamos, si esto\n",
        "fuea verdad ¿qué tan probable es la muestra que tengo?\n",
        "\n",
        "-   Llamamos la hipótesis a probar Ho, y su alternativa H1.\n",
        "\n",
        "![](img/prueba_hip2.png)\n",
        "\n",
        "![](img/prueba_hip3.png)\n",
        "\n",
        "### Errores y P-valor\n",
        "\n",
        "Asociada esta prueba, entonces, hay asociados dos tipos de errores:\n",
        "\n",
        "![](img/prueba_hip.png)\n",
        "\n",
        "-   Tipo I: Rechazar Ho cuando es cierta\n",
        "-   Tipo II: No rechazar Ho cuando es falsa.\n",
        "\n",
        "![](img/prueba_errores.png)\n",
        "\n",
        "![](img/prueba_errores2.png)\n",
        "\n",
        "-   Se elige nivel de significancia de contraste (α) = probabilidad de\n",
        "    cometer error Tipo I. Típicamente α = 0,01, 0,05, 0,10.\n",
        "\n",
        "-   Para contrastar una hipótesis con su alternativa, debemos elegir:\n",
        "\n",
        "    1.  Un estadístico de contraste\n",
        "    2.  Una regla de rechazo, la cual depende de un valor crítico.\n",
        "\n",
        "    ![](https://www.dropbox.com/s/7cme0p3q8fyiep2/ic.png?raw=1)\n",
        "\n",
        "### Prueba de significancia\n",
        "\n",
        "Definimos la prueba de hipótesis de **significancia** como aquella que\n",
        "indica si un estimador $\\hat{T}$ es 0.\n",
        "\n",
        "$$ H_0: T =0\\text{ vs }H_1: T \\neq 0 $$\n",
        "\n",
        "El **Valor de probabilidad (ó p-valor)** es el nivel probabilidad más\n",
        "alto para el cual no podemos rechazar la hipótesis nula de la prueba de\n",
        "significancia.\n",
        "\n",
        "Ejemplo: \\$H_0: \\mu=0 \\$ y en la muestra especifica t= 1.52:\n",
        "\n",
        "$$ P-valor = P(T>1.52 \\vert h_0)= 1- \\phi(1.52)=0.0065$$\n",
        "\n",
        "-   el mayor nivel de significancia estadistica al cual no rechazamos\n",
        "    $H_0$ es 6.5%\n",
        "\n",
        "-   la probabilidad de observar un velor $T\\geq 1.52$ cuando $H_0$ es\n",
        "    cierta es en un 6.5 de las muestras.\n",
        "\n",
        "-   P-valores bajos dan evidencia en contra de $H_0$, ya que la\n",
        "    probabilidad de observarlo si $H_0$ es cierta es bajo.\n",
        "\n",
        "### Ejemplo de aplicación: Peso de los Pingüinos Palmer\n",
        "\n",
        "Consideremos los datos de los *pingüinos Palmer*. Los datos \"Palmer\n",
        "Penguins\" son un conjunto que detalla medidas morfológicas y\n",
        "características de tres especies de pingüinos: Adelie, Gentoo y\n",
        "Chinstrap. Recopilados por el Dr. Bill Link y su equipo. (Horst AM, Hill\n",
        "AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica)\n",
        "penguin data. doi:10.5281/zenodo.3960218, R package version 0.1.0,\n",
        "https://allisonhorst.github.io/palmerpenguins/index.html)\n",
        "\n",
        "![](https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png)\n"
      ],
      "id": "2180a2ee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar el conjunto de datos \"Penguins\"\n",
        "penguins = sns.load_dataset(\"penguins\")\n",
        "\n",
        "penguins.head()"
      ],
      "id": "dfdc731e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el contexto de los pingüinos y el peso de su población, podríamos\n",
        "tomar una muestra de pingüinos y calcular un intervalo de confianza para\n",
        "el peso promedio. Esto nos daría una estimación del peso promedio de la\n",
        "población total, junto con la confianza en que este valor estimado es\n",
        "preciso.\n",
        "\n",
        "Es importante tener en cuenta que el proceso de inferencia estadística\n",
        "se basa en suposiciones y en el uso adecuado de técnicas estadísticas.\n",
        "\n",
        "La elección de la muestra, la interpretación de los resultados y el\n",
        "nivel de confianza seleccionado son aspectos cruciales para realizar\n",
        "inferencias precisas y significativas.\n",
        "\n",
        "Relicemos algunos ejemplos de pruebas de hipótesis, sobre el peso de los\n",
        "pingüinos.\n",
        "\n",
        "Primero calcularemos el promedio muestral y lo veremos en el contexto de\n",
        "los datos observados:\n"
      ],
      "id": "682cc999"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular el promedio del peso de los pingüinos\n",
        "promedio_peso = penguins['body_mass_g'].mean()\n",
        "\n",
        "# Crear un histograma de la distribución del peso con el promedio\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=penguins, x='body_mass_g', bins=20, kde=True)\n",
        "plt.axvline(x=promedio_peso, color='red', linestyle='dashed', label='Promedio')\n",
        "plt.title('Distribución de Peso de Pingüinos')\n",
        "plt.xlabel('Masa Corporal (g)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "7ef48781",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestra idea de la inferencia, es aprovechar las propiedades del\n",
        "promedio muestral. De que es el promedio muestral el que se distribuye\n",
        "normal, su media es la media poblacional y conocemos sus\n",
        "características.\n",
        "\n",
        "Por ejemplo, consideremos que de esta población de pingüinos obtenemos\n",
        "1000 muestras de 50 individuos cada una. Si graficamos sus medias,\n",
        "podremos ver que estas se distribuyen aproximadamente normal.\n",
        "\n",
        "-   Si reducimos el tamaño de muestra, más nos alejamos de la\n",
        "    distribución normal.\n",
        "-   Si reducimos el número de repeticiones tambieé.\n"
      ],
      "id": "e5f165a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definir el tamaño de cada muestra y la cantidad de muestras\n",
        "tamano_muestra = 50\n",
        "cantidad_muestras = 10000\n",
        "\n",
        "# Crear una lista para almacenar las medias de cada muestra\n",
        "medias_muestras = []\n",
        "\n",
        "# Realizar el muestreo y cálculo de medias para cada muestra\n",
        "for _ in range(cantidad_muestras):\n",
        "    muestra = np.random.choice(penguins['body_mass_g'], size=tamano_muestra, replace=False)\n",
        "    media_muestra = np.mean(muestra)\n",
        "    medias_muestras.append(media_muestra)\n",
        "\n",
        "# Calcular el promedio de los promedios de las muestras\n",
        "promedio_promedios = np.mean(medias_muestras)\n",
        "\n",
        "# Crear el gráfico de las medias de las muestras\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(medias_muestras, bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=promedio_promedios, color='red', linestyle='dashed', label='Promedio de Promedios')\n",
        "plt.title('Distribución de Medias de Muestras')\n",
        "plt.xlabel('Media de Muestra de Peso (g)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "a020b269",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Intervalo de confianza\n",
        "\n",
        "Obtengamos una muestra y calculemos un intervalo de confianza:\n"
      ],
      "id": "9d8510ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Obtener una muestra simple de 40 pingüinos\n",
        "sample_size = 40\n",
        "sample = np.random.choice(penguins[\"body_mass_g\"], size=sample_size)\n",
        "\n",
        "# Calcular el error estándar de la media muestral\n",
        "sample_std = np.std(sample, ddof=1)  # Usar ddof=1 para calcular la desviación estándar muestral\n",
        "standard_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "# Nivel de confianza (por ejemplo, 95%)\n",
        "confidence_level = 0.95\n",
        "\n",
        "# Calcular el margen de error\n",
        "margin_of_error = stats.t.ppf((1 + confidence_level) / 2, df=sample_size - 1) * standard_error\n",
        "\n",
        "# Calcular el intervalo de confianza\n",
        "sample_mean = np.mean(sample)\n",
        "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
        "\n",
        "print(\"Intervalo de Confianza para el Peso:\")\n",
        "print(confidence_interval)"
      ],
      "id": "4bee46c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El resultado será un rango de valores dentro del cual es probable que se\n",
        "encuentre el verdadero peso promedio de los pingüinos en la población,\n",
        "con un nivel de confianza del 95%.\n",
        "\n",
        "¿Como nos fue? ¿Contiene al verdadero valor?\n",
        "\n",
        "### Comparaciones de grupos\n",
        "\n",
        "Ahora consideremos que tenemos grupos que queremos comparar.\n",
        "\n",
        "Si hacemos una grafica de distribución de tamaño por especie y sexo,\n",
        "podriamos empezar a analizar diferencias entre los grupos.\n"
      ],
      "id": "a19adeef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Crear la tabla de doble entrada por tipo y sexo de los pinguinos\n",
        "tabla_doble_entrada = penguins.groupby(['species', 'sex'])['body_mass_g'].agg(['mean', 'var']).reset_index()\n",
        "\n",
        "# Renombrar las columnas para mayor claridad\n",
        "tabla_doble_entrada.rename(columns={'mean': 'Promedio', 'var': 'Varianza'}, inplace=True)\n",
        "\n",
        "# Mostrar la tabla de doble entrada\n",
        "tabla_doble_entrada"
      ],
      "id": "fdf2ddea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podriamos querer saber si el peso es diferente para los pinguinos de la\n",
        "especie Adelie, para diferentes sexos:\n",
        "\n",
        "**Pregunta de Prueba de Hipótesis:**\n",
        "\n",
        "¿Existe una diferencia significativa en el peso promedio entre los\n",
        "pingüinos machos y las pingüinas hembras en la especie \"Adelie\"?\n",
        "\n",
        "-   Hipótesis Nula (H0):\n",
        "\n",
        "No hay diferencia significativa en el peso promedio entre los pingüinos\n",
        "machos y las pingüinas hembras en la especie \"Adelie\".\n",
        "\n",
        "-   Hipótesis Alternativa (H1):\n",
        "\n",
        "Existe una diferencia significativa en el peso promedio entre los\n",
        "pingüinos machos y las pingüinas hembras en la especie \"Adelie\".\n",
        "\n",
        "Para probar esta hipótesis, podrías utilizar una prueba de hipótesis\n",
        "para comparar las medias de las muestras de peso de los pingüinos machos\n",
        "y hembras en la especie \"Adelie\". Esto te permitiría determinar si la\n",
        "diferencia observada en el peso promedio es lo suficientemente grande\n",
        "como para considerarse estadísticamente significativa.\n"
      ],
      "id": "93f7bf54"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el conjunto de datos \"Penguins\"\n",
        "penguins = sns.load_dataset(\"penguins\")\n",
        "\n",
        "# Filtrar los pingüinos de la especie \"Adelie\"\n",
        "adelie_penguins = penguins[penguins['species'] == 'Adelie']\n",
        "\n",
        "# Crear un histograma para la distribución de peso por sexo\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=adelie_penguins, x='body_mass_g', hue='sex', bins=20, kde=True)\n",
        "plt.title('Distribución de Peso por Sexo para Pingüinos Adelie')\n",
        "plt.xlabel('Masa Corporal (g)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.legend(title='Sexo')\n",
        "plt.show()"
      ],
      "id": "53423411",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple vista podriamos pensar ambos grupos son diferentes. Es más\n",
        "claro si dibujamos el promedio muestral observado.\n"
      ],
      "id": "26a4391b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Crear un gráfico de densidad con líneas de promedio\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(data=adelie_penguins, x='body_mass_g', hue='sex', fill=True, common_norm=False)\n",
        "plt.axvline(x=adelie_penguins.groupby('sex')['body_mass_g'].mean()['Female'], color='blue', linestyle='dashed', label='Promedio Femenino')\n",
        "plt.axvline(x=adelie_penguins.groupby('sex')['body_mass_g'].mean()['Male'], color='orange', linestyle='dashed', label='Promedio Masculino')\n",
        "plt.title('Densidad de Peso por Sexo para Pingüinos Adelie')\n",
        "plt.xlabel('Masa Corporal (g)')\n",
        "plt.ylabel('Densidad')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "ecf7c21c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si construimos una prueba t de diferencia de medias:\n"
      ],
      "id": "85305170"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cargar el conjunto de datos \"Penguins\"\n",
        "penguins = sns.load_dataset(\"penguins\")\n",
        "\n",
        "# Filtrar los pingüinos de la especie \"Adelie\"\n",
        "adelie_penguins = penguins[penguins['species'] == 'Adelie']\n",
        "\n",
        "# Filtrar machos y hembras\n",
        "machos = adelie_penguins[adelie_penguins['sex'] == 'Male']\n",
        "hembras = adelie_penguins[adelie_penguins['sex'] == 'Female']\n",
        "\n",
        "# Realizar la prueba t independiente\n",
        "t_statistic, p_value = stats.ttest_ind(machos['body_mass_g'], hembras['body_mass_g'], equal_var=False)\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Estadística t:\", t_statistic)\n",
        "print(\"Valor p:\", p_value)\n",
        "\n",
        "# Crear un gráfico de comparación de peso\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=[machos['body_mass_g'], hembras['body_mass_g']], palette=['blue', 'pink'])\n",
        "plt.title('Comparación de Peso entre Machos y Hembras de Pingüinos Adelie')\n",
        "plt.xticks([0, 1], ['Machos', 'Hembras'])\n",
        "plt.ylabel('Peso (g)')\n",
        "plt.show()"
      ],
      "id": "f03b9eda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, podriamos querer comparar hembras y machos de diferentes\n",
        "Islas. Para esto podriamos usar una prueba ANOVA.\n",
        "\n",
        "En este código, primero cargamos el conjunto de datos \"Penguins\" y luego\n",
        "creamos dos subconjuntos separados para machos y hembras. Después,\n",
        "utilizamos la función stats.f_oneway() para realizar una prueba ANOVA\n",
        "para comparar los pesos entre hembras y machos. El resultado incluye la\n",
        "estadística F y el valor p.\n",
        "\n",
        "El valor p nos indica si hay una diferencia significativa entre los\n",
        "grupos. Si el valor p es menor que un umbral de significancia (por\n",
        "ejemplo, 0.05), podríamos rechazar la hipótesis nula y concluir que hay\n",
        "una diferencia significativa en el peso entre hembras y machos de\n",
        "diferentes islas.\n",
        "\n",
        "Recuerda que, antes de realizar una prueba ANOVA, es importante\n",
        "verificar las suposiciones necesarias, como la normalidad y la\n",
        "homogeneidad de varianzas en los grupos. Si estas suposiciones no se\n",
        "cumplen, podría ser necesario considerar otras pruebas estadísticas o\n",
        "transformaciones de los datos.\n"
      ],
      "id": "a64187a0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Cargar el conjunto de datos \"Penguins\"\n",
        "penguins = sns.load_dataset(\"penguins\")\n",
        "\n",
        "# Filtrar machos y hembras\n",
        "machos = penguins[penguins['sex'] == 'Male']\n",
        "hembras = penguins[penguins['sex'] == 'Female']\n",
        "\n",
        "# Realizar una prueba ANOVA\n",
        "result = stats.f_oneway(machos['body_mass_g'], hembras['body_mass_g'])\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Estadística F:\", result.statistic)\n",
        "print(\"Valor p:\", result.pvalue)"
      ],
      "id": "f323cd3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Cargar el conjunto de datos \"Penguins\"\n",
        "penguins = sns.load_dataset(\"penguins\")\n",
        "\n",
        "# Filtrar machos y hembras\n",
        "machos = penguins[penguins['sex'] == 'Male']\n",
        "hembras = penguins[penguins['sex'] == 'Female']\n",
        "\n",
        "# Realizar una prueba ANOVA\n",
        "result = stats.f_oneway(machos['body_mass_g'], hembras['body_mass_g'])\n",
        "\n",
        "# Calcular las medias de peso por género e isla\n",
        "medias_peso = penguins.groupby(['species', 'island', 'sex'])['body_mass_g'].mean().reset_index()\n",
        "\n",
        "# Crear un gráfico de barras con puntos y intervalos de confianza\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=medias_peso, x='species', y='body_mass_g', hue='sex', errorbar='sd', palette=['pink', 'blue'])\n",
        "#sns.boxplot(data=medias_peso, x='species', y='body_mass_g', hue='sex', palette=['blue', 'pink'])\n",
        "plt.title('Comparación de Peso entre Hembras y Machos por Isla')\n",
        "plt.xlabel('Especie e Isla')\n",
        "plt.ylabel('Media de Peso (g)')\n",
        "plt.legend(title='Sexo')\n",
        "plt.show()"
      ],
      "id": "b4de42ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimentos Aleatorios y pruebas A/B\n",
        "\n",
        "Un experimento estadístico es un enfoque científico que busca establecer\n",
        "relaciones de causalidad y obtener conclusiones sobre cómo ciertas\n",
        "variables afectan a otras. Los experimentos estadísticos se diseñan para\n",
        "manipular deliberadamente una o más variables independientes y observar\n",
        "los efectos que tienen sobre una variable dependiente. Al controlar y\n",
        "manipular las variables de interés, los experimentos permiten a los\n",
        "investigadores hacer afirmaciones más sólidas sobre las relaciones\n",
        "causales.\n",
        "\n",
        "Una prueba A/B, también conocida como prueba de división, es una técnica\n",
        "utilizada en la investigación y el análisis para comparar dos variantes\n",
        "o grupos con el fin de determinar cuál de ellos produce un mejor\n",
        "resultado en términos de rendimiento, efectividad o preferencia. En una\n",
        "prueba A/B, se selecciona un grupo de muestra y se divide en dos grupos,\n",
        "uno que experimenta la variante \"A\" (por ejemplo, una versión actual) y\n",
        "otro que experimenta la variante \"B\" (por ejemplo, una versión\n",
        "modificada). Luego, se recopilan datos y se comparan los resultados de\n",
        "ambos grupos para determinar cuál variante es más efectiva. Las pruebas\n",
        "A/B son comunes en marketing, diseño de productos y desarrollo web para\n",
        "tomar decisiones informadas sobre mejoras y optimizaciones.\n",
        "\n",
        "Las pruebas A/B es son ampliamente utilizado en diversas áreas, como el\n",
        "marketing, la investigación de usuarios y el diseño de productos. En una\n",
        "prueba A/B, se seleccionan dos grupos de muestra: uno experimenta la\n",
        "versión original (A) y el otro experimenta una variante modificada (B).\n",
        "La idea detrás de una prueba A/B es evaluar si la variante B produce un\n",
        "efecto significativamente diferente en una métrica de interés en\n",
        "comparación con la variante A.\n",
        "\n",
        "Mediante la asignación aleatoria de los participantes a los grupos A y\n",
        "B, y al controlar las condiciones en las que se les presenta cada\n",
        "variante, se reduce la posibilidad de sesgos y se permite un análisis\n",
        "causal más confiable. Al comparar las diferencias observadas en los\n",
        "resultados entre los grupos A y B, es posible inferir si la variante B\n",
        "tiene un impacto significativo en la variable de interés.\n",
        "\n",
        "Sin embargo, es importante tener en cuenta que aunque las pruebas A/B\n",
        "proporcionan evidencia de asociación causal, no garantizan que la\n",
        "causalidad sea absoluta. Otros factores no controlados pueden influir en\n",
        "los resultados. Para obtener una comprensión más completa de la\n",
        "causalidad, los experimentos controlados aleatorizados y el uso de\n",
        "métodos de diseño experimental sólidos son esenciales. Las pruebas A/B\n",
        "son una herramienta poderosa para explorar causas y efectos en\n",
        "condiciones controladas y analizar el rendimiento relativo de diferentes\n",
        "opciones.\n",
        "\n",
        "Veamos un ejemplo en la práctica. Este es parte del ejercicio de\n",
        "aplicación.\n",
        "\n",
        "## Caso: **Aplicación de A/B testing para promoción de Marketing**\n",
        "\n",
        "### Enunciado\n",
        "\n",
        "Imaginemos que trabajamos en una empresa de e-commerce que vende\n",
        "productos electrónicos y queremos aumentar las ventas en una línea de\n",
        "productos específica, como teléfonos móviles.\n",
        "\n",
        "Para ello, decidimos utilizar una promoción de ventas basada en una\n",
        "ruleta lúdica que ofrecerá descuentos a los clientes que la utilicen.\n",
        "\n",
        "Para implementar la promoción, primero seleccionamos aleatoriamente un\n",
        "grupo de clientes y les enviamos un correo electrónico con un enlace a\n",
        "la ruleta lúdica. Al hacer clic en el enlace, los clientes son\n",
        "redirigidos a una página en la que pueden girar la ruleta y ganar un\n",
        "descuento en su próxima compra.\n",
        "\n",
        "Vamos a pensar que los clientes son asignados a uno de los siguientes\n",
        "grupos: - Control: no les da una promoción (mala suerte, intentalo otra\n",
        "vez) - Tratamiento 1: 20% de descuento en el producto - Tratamiento 2:\n",
        "Un complemento gratuito (carcasa) que tiene un costo para la empresa\n",
        "similar al descuento.\n",
        "\n",
        "### Creación de los datos\n",
        "\n",
        "Como nuestro caso es un ejemplo ficticio, vamos a crear los datos.\n",
        "\n",
        "Este código creará un conjunto de datos con 400 observaciones (200 en el\n",
        "grupo de control y 200 en el grupo de tratamiento), donde se simulan\n",
        "lascompras de cada usuario.\n"
      ],
      "id": "63f0fbf9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Define una semilla para la generación de números aleatorios\n",
        "np.random.seed(123)\n",
        "random.seed(123)\n",
        "\n",
        "# Crear un vector de 200 valores aleatorios para el grupo de control\n",
        "control = np.random.choice([\"Control\"], size=200, replace=True)\n",
        "\n",
        "# Crear un vector de 200 valores aleatorios para el grupo de tratamiento\n",
        "tratamiento = np.random.choice([\"Treatment 1\", \"Treatment 2\"], size=100, replace=True, p=[0.7, 0.3])\n",
        "\n",
        "# Crear un vector de número de compras para cada grupo\n",
        "control_compras = np.random.binomial(5, 0.2, size=200)\n",
        "tratamiento1_compras = np.random.binomial(5, 0.4, size=100)\n",
        "tratamiento2_compras = np.random.binomial(5, 0.6, size=100)\n",
        "\n",
        "# Combinar los vectores en un DataFrame\n",
        "data = {\n",
        "    'grupo': np.concatenate((control, np.repeat(\"Treatment\", 200))),\n",
        "    'tipo_tratamiento': np.concatenate((np.repeat(\"Control\", 200), np.repeat([\"Treatment 1\", \"Treatment 2\"], [100, 100]))),\n",
        "    'ventas': np.concatenate((control_compras, tratamiento1_compras, tratamiento2_compras))\n",
        "}\n",
        "\n",
        "ventas_df = pd.DataFrame(data)\n",
        "\n",
        "# Verificar el DataFrame\n",
        "ventas_df"
      ],
      "id": "22c91804",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: callout-warning\n",
        "#### Taller 1: Pregunta 3 -Ejemplo AB test en Marketing:\n",
        "\n",
        "Considere que tenemos los datos del banco mundial, del país que\n",
        "selecciono anteriormente, y desea aprender sobre alguna caracterpistica\n",
        "de dicho pais en el periodo.\n",
        "\n",
        "Escriba una pregunta de investigación que se pueda responder con los\n",
        "datos disponibles. ¿Cómo definiria la variable aleatoria relevante? ¿Qué\n",
        "hipótesis podria responder su pregunta?\n",
        "\n",
        "Estudiemos si la promoción fue efectiva en estos datos. Para esto:\n",
        "\n",
        "1.  Describa los resultados de la promocion para los diferentes grupos,\n",
        "    en terminos de estadisticas descriptivas.\n",
        "2.  Compare visualmente los resultados de los diferentes grupos.\n",
        "3.  ¿Fue la promocion efectiva? Use una prueba de hipotesis para\n",
        "    analizar el grupo tratado y de control.\n",
        "4.  ¿Cual de las promociones fue más efectiva? Use una prueba ANOVA.\n",
        ":::\n",
        "\n",
        "### Buenas prácticas en análisis de datos\n",
        "\n",
        "#### Importancia de la Adquisición y Almacenamiento de Datos\n",
        "\n",
        "La adquisición y el almacenamiento de datos son los cimientos sobre los\n",
        "cuales se construye todo el proceso de análisis. La calidad y la\n",
        "confiabilidad de los datos que obtengamos son fundamentales para\n",
        "asegurarnos de que los resultados y conclusiones que extraigamos sean\n",
        "precisos y relevantes. En esta sección, exploraremos la importancia de\n",
        "esta etapa y cómo afecta todo el flujo de trabajo de la ciencia de\n",
        "datos.\n",
        "\n",
        "Garantía de Calidad y Fiabilidad en la Obtención de Datos: Obtener datos\n",
        "confiables es el primer paso para garantizar que nuestras conclusiones\n",
        "sean sólidas. La calidad de los datos está relacionada con la precisión,\n",
        "integridad y consistencia de la información que recopilamos. Asegurarnos\n",
        "de que los datos sean precisos desde el principio minimiza la\n",
        "posibilidad de errores en análisis posteriores. Exploraremos técnicas y\n",
        "prácticas para verificar la calidad de los datos y cómo mitigar posibles\n",
        "fuentes de error.\n",
        "\n",
        "Exploración de Diferentes Fuentes de Datos y su Impacto en los\n",
        "Resultados: En el mundo actual, los datos provienen de diversas fuentes:\n",
        "bases de datos, encuestas, sensores, redes sociales, entre otros. Cada\n",
        "fuente tiene sus propias características y potenciales sesgos.\n",
        "Comprender las diferencias entre estas fuentes y cómo pueden influir en\n",
        "los resultados es crucial para tomar decisiones informadas. Analizaremos\n",
        "ejemplos de cómo la elección de la fuente de datos puede afectar las\n",
        "conclusiones y cómo evaluar la confiabilidad de las fuentes.\n",
        "\n",
        "#### Metodologías de Levantamiento y Adquisición de Datos:\n",
        "\n",
        "El proceso de obtención de datos implica una planificación cuidadosa.\n",
        "Exploraremos diversas metodologías utilizadas para recopilar datos,\n",
        "desde encuestas y experimentos hasta scraping de datos en línea. Cada\n",
        "metodología tiene sus propias ventajas y desventajas, y es importante\n",
        "seleccionar la más adecuada para los objetivos del análisis.\n",
        "Discutiremos cómo diseñar encuestas efectivas, cómo considerar la ética\n",
        "en la recopilación de datos y cómo aprovechar las fuentes de datos\n",
        "existentes.\n",
        "\n",
        "Esta sección nos proporcionará una base sólida para comprender cómo\n",
        "adquirir y almacenar datos de manera efectiva y confiable. Una vez que\n",
        "comprendamos cómo obtener datos de calidad, podremos avanzar con\n",
        "confianza en las etapas posteriores del proceso de análisis, sabiendo\n",
        "que estamos trabajando con una base sólida y confiable.\n",
        "\n",
        "#### Desafíos y Consideraciones:\n",
        "\n",
        "A medida que ingresamos al emocionante mundo del análisis de datos, nos\n",
        "encontramos con una serie de desafíos y consideraciones que debemos\n",
        "abordar de manera efectiva para garantizar el éxito de nuestro proyecto.\n",
        "Estos desafíos abarcan desde la protección de la privacidad de los datos\n",
        "hasta las complejidades de la limpieza y transformación durante la etapa\n",
        "de preparación.\n",
        "\n",
        "#### Privacidad y Seguridad de los Datos:\n",
        "\n",
        "Uno de los aspectos más críticos en el análisis de datos es la\n",
        "privacidad y seguridad de la información. Los datos pueden contener\n",
        "información sensible y personal, y es esencial proteger la\n",
        "confidencialidad de las personas y organizaciones involucradas.\n",
        "Exploraremos prácticas y regulaciones para garantizar que los datos se\n",
        "manejen de manera ética y legal. Discutiremos cómo anonimizar los datos,\n",
        "utilizar técnicas de enmascaramiento y seguir las mejores prácticas para\n",
        "resguardar la privacidad de los individuos.\n",
        "\n",
        "#### Limpieza y Transformación durante la Preparación de Datos:\n",
        "\n",
        "La etapa de preparación de datos es crucial para asegurarse de que los\n",
        "datos sean aptos para el análisis. Sin embargo, este proceso no está\n",
        "exento de desafíos. Los datos pueden contener valores faltantes,\n",
        "duplicados y errores que deben abordarse de manera adecuada.\n",
        "Exploraremos técnicas para identificar y manejar valores atípicos y\n",
        "faltantes, así como la importancia de la normalización y estandarización\n",
        "de los datos. Aprenderemos cómo transformar los datos en un formato\n",
        "adecuado para el análisis, incluida la reorganización de variables y la\n",
        "creación de nuevas características. En resumen, enfrentamos una serie de\n",
        "desafíos y consideraciones clave en nuestro viaje hacia el análisis de\n",
        "datos significativo. Desde la protección de la privacidad hasta la\n",
        "preparación efectiva de los datos, abordar estos desafíos de manera\n",
        "adecuada es esencial para garantizar que nuestras conclusiones sean\n",
        "sólidas, confiables y éticas.\n",
        "\n",
        "#### Reproducibilidad y Control de Versiones (GIT):\n",
        "\n",
        "Key ideas:\n",
        "\n",
        "-   Una documentacion detallada del analisis, de las desiciones tomadas.\n",
        "    -   Notebooks pueden ser una buena herramienta inicial.\n",
        "-   Importancia de mantener un registro de los cambios en los datos.\n",
        "-   Uso de sistemas de control de versiones como GIT para rastrear\n",
        "    cambios.\n",
        "-   Aplicación de control de versiones en proyectos de preparación de\n",
        "    datos.\n",
        "\n",
        "La reproducibilidad y el control de versiones son componentes\n",
        "fundamentales para garantizar la integridad y la transparencia en el\n",
        "análisis de datos. Además de mantener un registro detallado de las\n",
        "decisiones tomadas durante el proceso, el uso de sistemas de control de\n",
        "versiones como GIT se vuelve esencial para mantener la trazabilidad y la\n",
        "colaboración efectiva en proyectos de preparación y análisis de datos.\n",
        "\n",
        "**Documentación Detallada del Análisis y Uso de Notebooks:** Una\n",
        "documentación exhaustiva del análisis es esencial para comprender el\n",
        "flujo de trabajo, las decisiones tomadas y las transformaciones\n",
        "aplicadas a los datos. Los notebooks, como Jupyter Notebooks, ofrecen\n",
        "una herramienta excepcional para lograr esto. En cada celda de un\n",
        "notebook, es posible combinar explicaciones en lenguaje natural con\n",
        "código ejecutable y visualizaciones. Esto permite registrar no solo el\n",
        "qué y el cómo, sino también el porqué detrás de cada paso.\n",
        "\n",
        "**Importancia de Mantener un Registro de los Cambios en los Datos:**\n",
        "Cada decisión tomada durante la preparación y el análisis de datos puede\n",
        "tener un impacto significativo en los resultados finales. Mantener un\n",
        "registro detallado de estas decisiones, desde la limpieza de datos hasta\n",
        "la creación de variables derivadas, es crucial para comprender cómo se\n",
        "obtuvieron ciertos resultados. Una documentación precisa y detallada\n",
        "permite a otros analistas validar y replicar el análisis en el futuro.\n",
        "\n",
        "**Uso de Sistemas de Control de Versiones como GIT para Rastrear\n",
        "Cambios:**\n",
        "\n",
        "GIT, un sistema de control de versiones ampliamente utilizado, no solo\n",
        "se aplica al desarrollo de software, sino que también es una herramienta\n",
        "poderosa en el análisis de datos. Permite rastrear cada modificación\n",
        "realizada en el código y en los documentos, incluidos los notebooks.\n",
        "Cada cambio es registrado como un \"commit\", lo que proporciona un\n",
        "historial completo y auditable de las transformaciones realizadas en los\n",
        "datos.\n",
        "\n",
        "![Un esquema de git por Allison Horst\n",
        "@allison_horst](img/git_flujo_allison.jpeg)\n",
        "\n",
        "**Aplicación de Control de Versiones en Proyectos de Preparación de\n",
        "Datos:**\\* La aplicación de GIT en proyectos de preparación de datos\n",
        "agrega un nivel adicional de transparencia y colaboración. Los\n",
        "repositorios de GIT almacenan no solo los datos originales, sino también\n",
        "los notebooks y scripts utilizados en el proceso. Esto permite a los\n",
        "analistas colaborar en un entorno controlado y mantener un historial de\n",
        "cambios. En caso de que surjan problemas o se necesite retroceder en el\n",
        "tiempo, GIT ofrece la capacidad de volver a versiones anteriores de\n",
        "manera segura.\n",
        "\n",
        "La combinación de documentación detallada a través de notebooks y el uso\n",
        "de sistemas de control de versiones como GIT proporciona una base sólida\n",
        "para el análisis de datos reproducible y transparente. Esto no solo\n",
        "facilita la comprensión y validación de los resultados, sino que también\n",
        "fomenta la colaboración y la mejora continua en proyectos de preparación\n",
        "y análisis de datos.\n",
        "\n",
        "::: callout-tip\n",
        "#### Actividad de proyecto - Inicio reproducible\n",
        "\n",
        "Vamos a empezar el proyecto, dando los primeros pasos considerando que\n",
        "sea reproducible y transparente.\n",
        "\n",
        "Uno de los productos del proyecto es un notebook de reporte del\n",
        "análisis. Para esto, iremos avanzando desde hoy.\n",
        "\n",
        "1.  Defina a su grupo e inscribase.\n",
        "2.  Cree un repositorio de Github en el cual van a trabajar, agregue a\n",
        "    todos los integrantes como colaboradores y a la profesora (usuario:\n",
        "    melanieoyarzun)\n",
        "3.  Cree el readme listando a los integrantes del grupo.\n",
        "4.  Definan con que base de datos les gustaría trabajar.\n",
        "5.  Propongan una o dos preguntas de investigación y las hipotesis que\n",
        "    las responderían.\n",
        "\n",
        "La siguiente sesión, vamos a explorar los datos y empezar los primeros\n",
        "pasos en su análisis.\n",
        ":::"
      ],
      "id": "e34a9cf3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}